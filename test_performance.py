import cv2
import time
import numpy as np
import torch
from ultralytics import YOLO

# --- 0. Grayscale ì „ì²˜ë¦¬ ì„¤ì • ---
USE_GRAYSCALE = True  # True: grayscale ì „ì²˜ë¦¬ ì ìš©, False: ì›ë³¸ ì‚¬ìš©

CLIP_LIMIT = 2.0
GRID_SIZE = (8, 8)
SHARPEN_KERNEL = np.array([
    [0, -1,  0],
    [-1, 5, -1],
    [0, -1,  0]
], dtype=np.float32)

clahe = cv2.createCLAHE(clipLimit=CLIP_LIMIT, tileGridSize=GRID_SIZE)

def gray_sharpen_transform(img):
    """BGR image â†’ gray + CLAHE + sharpen â†’ 3ch BGR"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    enhanced = clahe.apply(gray)
    sharpened = cv2.filter2D(enhanced, -1, SHARPEN_KERNEL)
    return cv2.cvtColor(sharpened, cv2.COLOR_GRAY2BGR)

# --- 1. í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì • (í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •) ---

# [A. ğŸš€ Jetson Orin í…ŒìŠ¤íŠ¸ ì‹œ]
# (í…ŒìŠ¤íŠ¸í•˜ë ¤ëŠ” ëª¨ë¸ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”)
# MODEL_PATH = "ckpt/yolov8n_ep600_p70.pt"       # 1. PyTorch ì›ë³¸
# MODEL_PATH = "yolov8n_ep600_p70.onnx"      # 2. ONNX (FP16)
# MODEL_PATH = "/home/chai/Desktop/classifier/yolo_train/ckpt/1126_13sub_aug_best.engine"  # 3. TensorRT (FP16) - Best Performance

# Grayscale ëª¨ë¸ (ê¶Œì¥)
MODEL_PATH = "/home/chai/Desktop/classifier/product_classifier/src/yolo_models/1222_v8n_img480_best_aug_segment_gray.pt"

# [B. ğŸŸ¢ Intel N97 í…ŒìŠ¤íŠ¸ ì‹œ]
# (í…ŒìŠ¤íŠ¸í•˜ë ¤ëŠ” ëª¨ë¸ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”)
# MODEL_PATH = "ckpt/yolov8n_ep600_p70.pt"                  # 1. PyTorch ì›ë³¸ (CPU/GPU)
# MODEL_PATH = "yolov8n_ep600_p70_openvino_model/"     # 2. OpenVINO (FP16) - Best Performance

# ìë™ ë””ë°”ì´ìŠ¤ ê°ì§€
if torch.cuda.is_available():
    DEVICE = '0'  # CUDA GPU
else:
    DEVICE = 'cpu'  # CPU fallback

# â˜…â˜…â˜… 2ëŒ€ì˜ ì¹´ë©”ë¼ ì„¤ì • â˜…â˜…â˜…
CAMERA_INDICES = [0, 2]
# ----------------------------------------------------

print(f"Loading model: {MODEL_PATH}")
print(f"Using device: {DEVICE}")
print(f"Grayscale preprocessing: {'Enabled' if USE_GRAYSCALE else 'Disabled'}")

# 2. ëª¨ë¸ 1íšŒ ë¡œë“œ
try:
    model = YOLO(MODEL_PATH)
    print("Model loaded successfully.")
except Exception as e:
    print(f"Error loading model: {e}")
    exit()

# 3. ì—¬ëŸ¬ ì¹´ë©”ë¼ ë° FPS ì¹´ìš´í„° ì´ˆê¸°í™”
caps = []
p_times = {} # ê° ì¹´ë©”ë¼ë³„ë¡œ p_timeì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
window_names = []

for index in CAMERA_INDICES:
    cap = cv2.VideoCapture(index)
    if not cap.isOpened():
        print(f"Error: Could not open webcam {index}.")
    else:
        caps.append(cap)
        p_times[index] = 0  # FPS ê³„ì‚°ìš© ì‹œê°„ ì´ˆê¸°í™”
        window_name = f"YOLOv8 Test - Camera {index}"
        window_names.append(window_name)
        cv2.namedWindow(window_name)
        print(f"Opened Camera {index}")

if not caps:
    print("No cameras could be opened. Exiting.")
    exit()

print("Starting webcam feeds... (Press 'q' to quit)")

while True:
    
    for i, cap in enumerate(caps):
        cam_index = CAMERA_INDICES[i]
        window_name = window_names[i]
        
        ret, frame = cap.read()
        if not ret:
            print(f"Warning: Could not read frame from camera {cam_index}")
            continue

        # 4. ì „ì²˜ë¦¬ (grayscale + CLAHE + sharpen)
        if USE_GRAYSCALE:
            processed_frame = gray_sharpen_transform(frame)
        else:
            processed_frame = frame

        # 5. ì¶”ë¡ 
        results = model.predict(processed_frame, device=DEVICE, verbose=False)

        # 6. FPS ê³„ì‚° (ì¹´ë©”ë¼ë³„)
        c_time = time.time()
        current_p_time = p_times[cam_index]
        if current_p_time > 0:
            fps = 1 / (c_time - current_p_time)
        else:
            fps = 0  # ì²« í”„ë ˆì„
        p_times[cam_index] = c_time

        # 7. ê²°ê³¼ ì‹œê°í™” (ì „ì²˜ë¦¬ëœ í”„ë ˆì„ì— í‘œì‹œ)
        annotated_frame = results[0].plot()

        # 8. ì •ë³´ í‘œì‹œ (FPS, ì¹´ë©”ë¼ ID, ëª¨ë¸, ì „ì²˜ë¦¬ ìƒíƒœ)
        gray_status = "GRAY" if USE_GRAYSCALE else "COLOR"
        cv2.putText(annotated_frame, f"Cam {cam_index} | FPS: {int(fps)} | {gray_status}", (10, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(annotated_frame, f"Model: {MODEL_PATH.split('/')[-1]}", (10, 80),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        # 9. ê°œë³„ ì°½ì— í‘œì‹œ
        cv2.imshow(window_name, annotated_frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# 9. ì •ë¦¬
for cap in caps:
    cap.release()
cv2.destroyAllWindows()
print("Test finished.")